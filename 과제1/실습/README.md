# 과제1. 



> ###  1. SageMaker Linear Learner


- 분류/회귀 작업을 수행하기 위한 방법
- 해당 실습에서는 회귀를 주로 사용함
- 회귀에서 사용하는 검증 행렬
    - 평균 제곱 오차, 루트 평균 제곱 오차, 크로스 엔트로피 손실, 절대 오류
- 분류의 경우
    - 분류, 재현도, 정확도, F1


---
> ### 2, 선형 학습자의 적용 사례
1. 회귀 작업의 경우 연속적인 숫자(년도 등)이 적용 되어야함
2. 이산 이중 분류에 적용 가능
    - 환자 치료 필요 유무 등
3. 다중 분류
    - 자율주행 자동차 신호 인식에 필요

---
> ### 3. 선형 학습자 개요
### 1) 사전 작업
- 데이터가 섞여 있는지 확인 필요
    - 모델이 데이터의 순서를 학습하지 않게 하기 위해 데이터를 무작위로 배치
### 2) 모델 훈련
- 기능 스케일링 정규화
    - 선형 학습자에서 제공
    - 단일 기능의 가중치에 의해 지배되지 않도록 하는 기능
- 경사 하강법
    - 최적의 매개 변수를 최적화하고 근사하기 위한 방법
- 과적합을 방지하기 위해 L1, L2 정규화를 사용
### 3) 모델 검증
- 모델 학습 후 검증 진행
- 평가 데이터에 대해 학습된 모델들이 검증됨
> ### 4. 선형 학습자의 하이퍼 파라미터
- feature_dim: 입력 데이터에 있는 기능의 개수
    - 해당 실습에서는 경력 년수라는 하나의 기능만 있음
- num_classes: 클래스의 개수
    - 타깃으로 지정해 줄클래수의 개수
- epochs: 얼마나 많은 학습 데이터를 사용할 것인가
    - 머신러닝에서는 학습을 많이 반복하지 않음
    - 학습 데이터를 여러 번 입력하고 파라미터를 업데이트해주는데 이가 epochs임
- learning_rate: 학습률
    - 학습률이 높으면 빠르게 적합한 값인 최소점에 도달함
    - 낮으면 최적화에 늦게 도달함(손실)
    - 해당 과제에서는 제곱 손실, 절대 제곱 손실 방법을 사용하여 최소화, 최적화의 방법을 찾음
- mini_batch_size: 
    - 학습 데이터를 배치로 나누면 그것이 배치 사이즈임
    - 기본 값은 1000
- num_models: 모델의 개수
    - 사용하는 수많은 모델의 개수
    - 이들을 기반으로 최상의 모델 선택 가능
- optimizer: 최적기의 유형
    - 자동, 확률적 경사 하강, Adam최족기, rmsprop 등을 선택 가능
--- 
> ### 5. 데이터 
### 1) AMS SageMaker의 선형 학습자는 다양한 입력 데이터 타입을 지원한다.
- Record IO
    - 데이터를 기록 형식으로 변환하여 모델을 학습시키기 위한 방법
    - Float32 tensor타입만 지원
- Text/csv
- File or pipe mode
- ### 2) 추론의 경우
- json 형식을 지원하는 초기 학습 알고리즘 사용 가능
    - 예측 및 추론 시 결과의 반환은 json
- ### 2) 회귀의 경우
- 예측 변수 유형을 회귀자로 선택해야한다.
    - 이중 분류/다중 분류 모두 사용

> ### 6. About EC2 인스턴스
- 선형 학습 알고리즘은 단일 CPU와 GPU 인스턴스를 기반으로 학습시킬 수 있다.
